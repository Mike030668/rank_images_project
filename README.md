# Rank Images Project

[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

Инструмент для ранжирования изображений на основе текстовых промптов и внутреннего качества, используя современные модели искусственного интеллекта: **SigLIP-2**, **Florence-2**, **CLIP-IQA**, **DINOv2**, **BLIP-2 (Image-Text Matching)**, **BLIP Caption + BERTScore** , **BLIP-2 Caption + BERTScore** и  **ImageReward**.
Ранжирование происходит на основе комбинированного балла, рассчитанного из **восьми метрик**:

## Содержание

- [Описание](#описание)
  - [Формула итогового балла](#формула-итогового-балла)
- [Возможности](#возможности)
- [Установка](#установка)
- [Использование](#использование)
  - [Быстрый старт с демонстрацией](#быстрый-старт-с-демонстрацией)
  - [Ранжирование ваших изображений](#ранжирование-ваших-изображений)
  - [Настройка пайплайна с помощью JSON-конфигурации](#настройка-пайплайна-с-помощью-json-конфигурации)
  - [Аргументы командной строки](#аргументы-командной-строки)
- [Структура проекта](#структура-проекта)
- [Лицензия](#лицензия)

## Описание

Этот проект предоставляет скрипт командной строки (`rank-images`), который позволяет упорядочить коллекцию изображений. Ранжирование происходит на основе комбинированного балла, рассчитанного из **семи метрик**:

1.  **Схожесть изображения и текста (SigLIP-2):** Оценивает, насколько изображение соответствует позитивным текстовым запросам и отличается от негативных.
2.  **Поиск объектов по запросу (Florence-2):** Проверяет, насколько успешно Florence-2 может обнаружить объекты, описанные в позитивных промптах, на изображении. Для формирования итогового балла метрики также вычисляется средний скор для негативных промптов, и из результата для позитивных промптов вычитается результат для негативных.
3.  **Общее качество изображения (CLIP-IQA):** Дает оценку общего визуального качества изображения.
4.  **Внутренняя структура (DINOv2):** Косвенно оценивает "структурированность" или богатство деталей изображения.
5.  **Соответствие изображения тексту (BLIP-2 ITM):** Оценивает вероятность соответствия изображения отдельным позитивным промптам, используя специализированную модель BLIP-2 для Image-Text Matching. Для формирования итогового балла метрики также вычисляется средний скор для негативных промптов, и из результата для позитивных промптов вычитается результат для негативных.
6.  **Соответствие описания промпту (BLIP Caption + BERTScore):** Генерирует описание изображения с помощью модели BLIP и оценивает семантическое сходство этого описания с исходным промптом с помощью метрики BERTScore.
7.  **Соответствие описания промпту (BLIP-2 Caption + BERTScore):** Генерирует описание изображения с помощью модели BLIP-2 и оценивает семантическое сходство этого описания с исходным промптом с помощью метрики BERTScore.
8. **Human-Preference Score (ImageReward):** Обученная на 137k человеческих предпочтениях reward-модель (0–10), захватывающая композицию и стиль.

Каждая метрика имеет свой вес (alpha, beta, gamma, delta, epsilon, zeta, theta), который можно настроить. Модели оптимизированы для работы как на GPU (с экономией VRAM), так и на CPU.

### Формула итогового балла

Итоговый балл (`total`) для каждого изображения вычисляется как нормализованная взвешенная сумма значений **включённых** метрик. Каждая метрика сначала вычисляется с учетом позитивных и негативных промптов (если применимо), а затем нормализуется.

**Доступные метрики:**

| Метрика | Имя в коде | Вес по умолчанию | Описание |
| :--- | :--- | :--- | :--- |
| **Схожесть изображения и текста (SigLIP-2)** | `sig` | `alpha` (0.6) | Оценивает, насколько изображение соответствует позитивным текстовым запросам и отличается от негативных. |
| **Поиск объектов по запросу (Florence-2)** | `flor` | `beta` (0.4) | Проверяет, насколько успешно Florence-2 может обнять объекты, описанные в позитивных промптах, на изображении. Для формирования итогового балла метрики также вычисляется средний скор для негативных промптов, и из результата для позитивных промптов вычитается результат для негативных. |
| **Общее качество изображения (CLIP-IQA)** | `iqa` | `gamma` (0.2) | Дает оценку общего визуального качества изображения. |
| **Внутренняя структура (DINOv2)** | `dino` | `delta` (0.1) | Косвенно оценивает "структурированность" или богатство деталей изображения. |
| **Соответствие изображения тексту (BLIP-2 ITM)** | `blip2` | `epsilon` (0.3) | Оценивает вероятность соответствия изображения отдельным позитивным промптам, используя специализированную модель BLIP-2 для Image-Text Matching. Для формирования итогового балла метрики также вычисляется средний скор для негативных промптов, и из результата для позитивных промптов вычитается результат для негативных. |
| **Соответствие описания промпту (BLIP Caption + BERTScore)** | `blip_cap` | `zeta` (0.25) | Генерирует описание изображения с помощью модели BLIP и оценивает семантическое сходство этого описания с исходным промптом с помощью метрики BERTScore. |
| **Соответствие описания промпту (BLIP-2 Caption + BERTScore)** | `blip2_cap` | `theta` (0.2) | Генерирует описание изображения с помощью модели BLIP-2 и оценивает семантическое сходство этого описания с исходным промптом с помощью метрики BERTScore. |
| **Human Preference Score (ImageReward)** | `imr` | `phi` (0.3) | Оценивает изображение на основе предпочтений человека (0–10), обученная на 137k человеческих оценках. |

**Общая логика вычисления:**

1.  **Вычисление исходных баллов метрик (`raw_score`)**:
    Для каждого изображения вычисляются **исходные** (ненормализованные) значения для **всех включённых** метрик. Используются только те метрики, которые указаны в списке `enabled_metrics` конфигурации пайплайна.
    *   **`sig` (SigLIP-2)**:
        ```
        raw_sig = get_siglip_score(image, positive_chunks_siglip) - get_siglip_score(image, negative_chunks_siglip)
        ```
    *   **`flor` (Florence-2)**:
        ```
        raw_flor = avg(get_florence_score(image, p) for p in positive_chunks_flor) - avg(get_florence_score(image, n) for n in negative_chunks_flor)
        ```
    *   **`iqa` (CLIP-IQA)**:
        ```
        raw_iqa = get_iqa(image)
        ```
        *(Не использует промпты)*
    *   **`dino` (DINOv2)**:
        ```
        raw_dino = get_dino(image)
        ```
        *(Не использует промпты)*
    *   **`blip2` (BLIP-2 ITM)**:
        ```
        raw_blip2 = get_blip2_match_score(image, positive_chunks_blip2) - get_blip2_match_score(image, negative_chunks_blip2)
        ```
    *   **`blip_cap` (BLIP Caption + BERTScore)**:
        ```
        raw_blip_cap = get_blip_caption_bertscore(image, prompt)
        ```
        *(Использует основной `prompt`, не разбивая на чанки)*
    *   **`blip2_cap` (BLIP-2 Caption + BERTScore)**:
        ```
        raw_blip2_cap = get_blip2_caption_bertscore(image, prompt)
        ```
        *(Использует основной `prompt`, не разбивая на чанки)*
    *   **`imr` (ImageReward)**:
        ```
        raw_imr = get_imr(image, prompt)
        ```
        *(Использует основной `prompt`)*

2.  **Нормализация по Z-оценке (`z_score`)**:
    Для каждой **включённой** метрики вычисляется Z-нормализованное значение на основе всех изображений в наборе:
    ```
    z_sig     = (_z(raw_sig_scores) + 1e-8)     / (std(raw_sig_scores) + 1e-8)
    z_flor    = (_z(raw_flor_scores) + 1e-8)    / (std(raw_flor_scores) + 1e-8)
    z_iqa     = (_z(raw_iqa_scores) + 1e-8)     / (std(raw_iqa_scores) + 1e-8)
    z_dino    = (_z(raw_dino_scores) + 1e-8)    / (std(raw_dino_scores) + 1e-8)
    z_blip2   = (_z(raw_blip2_scores) + 1e-8)   / (std(raw_blip2_scores) + 1e-8)
    z_blip_cap= (_z(raw_blip_cap_scores) + 1e-8)/ (std(raw_blip_cap_scores) + 1e-8)
    z_blip2_cap=(_z(raw_blip2_cap_scores) + 1e-8)/(std(raw_blip2_cap_scores) + 1e-8)
    z_imr     = (_z(raw_imr_scores) + 1e-8)     / (std(raw_imr_scores) + 1e-8)
    ```
    *(Здесь `_z(score_array)` — это стандартная Z-оценка: `(score_array - mean(score_array)) / std(score_array)`. Добавление `1e-8` для численной стабильности.)*

3.  **Вычисление итогового нормализованного балла (`normalized_total`)**:
    Нормализованные баллы комбинируются с весами **только для включённых метрик**:
    ```
    normalized_total = sum(
        weight_map[m] * res_dict.get(f"{m}_norm", 0.0) for m in enabled_metrics_list
    )
    ```
    Где `weight_map` — это словарь весов:
    ```python
    weight_map = {
        "sig": alpha,
        "flor": beta,
        "iqa": gamma,
        "dino": delta,
        "blip2": epsilon,
        "blip_cap": zeta,
        "blip2_cap": theta,
        "imr": phi, # <-- НОВОЕ
    }
    ```

4.  **Финальный итоговый балл (`total`)**:
    Чтобы получить значение в привычном диапазоне и учесть сумму весов, итоговый балл нормализуется:
    ```
    total = normalized_total / sum(weight_map[m] for m in enabled_metrics_list)
    ```
    Если сумма весов равна 0, `total` устанавливается в 0.

**Важно:** Весовые коэффициенты (`alpha`, `beta`, `gamma`, `delta`, `epsilon`, `zeta`, `theta`, `phi`) по умолчанию подобраны для демонстрационных данных. Для получения наилучших результатов на ваших собственных наборах изображений **необходимо вручную подбирать** эти коэффициенты. Это позволяет точно настроить вклад каждой метрики в итоговое ранжирование, особенно при работе с разнородными примерами.

Каждая метрика имеет свой вес (alpha, beta, gamma, delta, epsilon ...), который можно настроить. Модели оптимизированы для работы как на GPU (с экономией VRAM), так и на CPU.

## Возможности

-   **Экономия VRAM:** Модели SigLIP-2, DINOv2, BLIP-2 ITM, BLIP Caption и BLIP-2 Caption временно загружаются на GPU только во время вычислений. Florence-2 использует автоматическое распределение (`device_map="auto"`).
-   **Поддержка GPU и CPU:** Автоматическое определение наличия CUDA.
-   **Гибкие промпты:** Поддержка JSON-файлов с позитивными/негативными промптами или простых текстовых строк.
-   **Разбиение длинных текстов:** Автоматическое разбиение длинных промптов для SigLIP.
-   **Расширяемость:** Код структурирован для легкого добавления новых метрик.
-   **Гибкая настройка пайплайна:** Используйте JSON-файлы для определения, какие метрики использовать и с какими весами. Это позволяет легко создавать профили для разных задач ранжирования.
-   **Эффективность ресурсов:** Оптимизированная загрузка и использование моделей позволяют запускать проект на ограниченных ресурсах (например, локально с ~16GB RAM).

## Установка

Для установки проекта рекомендуется использовать `pip` или `uv pip`.

**Важно:** Проект требует **PyTorch >= 2.7.1**. Для его установки необходимо использовать **nightly** сборки с индекса PyTorch.

### Вариант 1: Используя `pip`

```bash
# 1. Клонируйте репозиторий
git clone https://github.com/Mike030668/rank_images_project.git
cd rank_images_project

# 2. (Рекомендуется) Создайте виртуальное окружение
python -m venv venv
# Активируйте его:
#   Linux/macOS: source venv/bin/activate
#   Windows:     venv\Scripts\activate

# 3. Установите проект и зависимости (editable mode)
   #    Используем --pre и дополнительный индекс для установки nightly PyTorch
#  (ImageReward требует git-репозиторий CLIP → укажем его явно)
pip install --pre \
  --extra-index-url https://download.pytorch.org/whl/nightly/cu121 \
  -e . \
  -r requirements.txt \
  -c constraints.txt


# 4. (Опционально) Установите дополнительные зависимости
# Для Jupyter-ноутбуков:
# pip install -e .[notebook]
```

### Вариант 2: Используя `uv pip` (если установлен `uv`)

`uv` значительно ускоряет установку зависимостей.

```bash
# 1. Клонируйте репозиторий
git clone https://github.com/Mike030668/rank_images_project.git
cd rank_images_project

# 2. (Рекомендуется) Создайте виртуальное окружение с помощью uv
uv venv

# 3. Активируйте его:
#   Linux/macOS: source .venv/bin/activate
#   Windows:     .venv\Scripts\activate

# 4. Установите проект и все основные зависимости
uv pip install --prerelease=allow \
  --extra-index-url https://download.pytorch.org/whl/nightly/cu121 \
  --index-strategy unsafe-best-match \
  -e .

# отдельно обновляем до нужных
uv pip install "timm>=0.9.2,<1.0" "fsspec==2025.3.0"

# 4a. проанрка
python - <<EOF
import timm, fsspec, datasets, ImageReward, torch, transformers
print("timm:      ", timm.__version__)       # 0.6.13
print("fsspec:    ", fsspec.__version__)     # 2025.3.0
print("datasets:  ", datasets.__version__)   # 2.13.0
print("ImageReward OK")                      # просто уверен, что нет ошибки импорта
print("torch:     ", torch.__version__)      # 2.7.1
print("transformers:", transformers.__version__)  # 4.53.1
EOF

# 5. (Опционально) Установите расширения
#   • Jupyter-ноутбуки
#       uv pip install -e .[notebook]
#   • Метрики на основе BERTScore (BLIP Caption, BLIP-2 Caption)

## Использование

После установки вы можете использовать команду `rank-images` из любого места, если ваше виртуальное окружение активно.

### Быстрый старт с демонстрацией

Проект включает демонстрационные изображения и промпты. Чтобы быстро проверить работу:

```bash
rank-images --demo
```

Это выполнит ранжирование изображений из папки `data/demo_images/` с использованием `data/demo_images/prompts.json`. Результат будет сохранен в `data/demo_images/ranking.csv`.

### Ранжирование ваших изображений

```bash
rank-images /путь/к/вашей/папке/с/изображениями --prompts /путь/к/prompts.json
```

**Пример:**

1.  Положите ваши изображения (`.jpg`, `.png`) в папку, например, `my_images/`.
2.  Создайте файл `my_prompts.json`:

    ```json
    {
      "prompt": "clear photo of a modern skyscraper, blue sky, high resolution",
      "prompt2": "sharp focus, detailed architecture",
      "negative": "blurry, low resolution, watermark, cartoon",
      "negative2": "night time, dark"
    }
    ```
3.  Запустите ранжирование:

    ```bash
    rank-images my_images --prompts my_prompts.json
    ```

4.  Результат будет записан в `my_images/ranking.csv`. Изображения будут отсортированы по убыванию итогового балла (`total`).

### Настройка пайплайна с помощью JSON-конфигурации

Вы можете определить, какие метрики использовать и с какими весами по умолчанию, с помощью JSON-файла конфигурации.

```bash
rank-images /путь/к/вашей/папке/с/изображениями \
  --prompts /путь/к/prompts.json \
  --pipeline-config configs/caption_focus_pipeline.json
```

**Примеры конфигурационных файлов:**

Файлы конфигурации находятся в папке `configs/`.

*   `configs/default_pipeline.json`: Использует все метрики с весами по умолчанию.
*   `configs/caption_focus_pipeline.json`: Фокусируется на метриках, связанных с генерацией описаний (captioning).
*   `configs/quality_and_alignment_pipeline.json`: Делает акцент на качестве изображения и соответствии запросу.

**Создание собственного конфига:**

Создайте файл, например, `my_custom_pipeline.json`:

```json
{
  "pipeline": {
    "enabled_metrics": ["sig", "flor", "iqa"],
    "default_weights": {
      "alpha": 0.5,
      "beta": 0.3,
      "gamma": 0.2,
      "delta": 0.0,
      "epsilon": 0.0,
      "zeta": 0.0,
      "theta": 0.0
    }
  },
  "processing": {
    "chunk_size": null
  }
}
```

И используйте его:

```bash
rank-images my_images --prompts my_prompts.json --pipeline-config my_custom_pipeline.json
```

### Аргументы командной строки

```bash
rank-images --help
```

```
usage: rank-images [-h] [--prompts PROMPTS] [--alpha ALPHA] [--beta BETA]
                   [--gamma GAMMA] [--delta DELTA] [--epsilon EPSILON]
                   [--zeta ZETA] [--theta THETA] [--phi PHI]
                   [--chunk CHUNK] [--demo] [--pipeline-config PIPELINE_CONFIG]
                   img_dir

Ранжирует изображения в заданной директории на основе текстовых промптов и
внутреннего качества, используя SigLIP-2, Florence-2, CLIP-IQA, DINOv2,
BLIP-2 (ITM), BLIP Caption + BERTScore, BLIP-2 Caption + BERTScore и ImageReward.

positional arguments:
  img_dir               Путь к директории с изображениями для ранжирования.

options:
  -h, --help            show this help message and exit
  --prompts PROMPTS     Источник текстовых промптов. Может быть:
                        - Путь к .json файлу с ключами 'prompt', 'prompt2',
                          'negative', 'negative2'.
                        - Произвольная текстовая строка (будет использована
                          как 'prompt').
                        Если не указан, ранжирование будет основано только на
                        именах файлов.
  --alpha ALPHA         Вес метрики SigLIP (схожесть изображения и текста).
                        По умолчанию 0.6.
  --beta BETA           Вес метрики Florence-2 (поиск объектов по запросу).
                        По умолчанию 0.4.
  --gamma GAMMA         Вес метрики CLIP-IQA (общее качество изображения).
                        По умолчанию 0.2.
  --delta DELTA         Вес метрики DINOv2 (внутренние признаки изображения).
                        По умолчанию 0.1.
  --epsilon EPSILON     Вес метрики BLIP-2 (Image-Text Matching).
                        По умолчанию 0.3.
  --zeta ZETA           Вес метрики BLIP Caption + BERTScore к prompt.
                        По умолчанию 0.25.
  --theta THETA         Вес метрики BLIP-2 Caption + BERTScore к prompt.
                        По умолчанию 0.2.
  --phi PHI             Вес метрики ImageReward (Human Preference Score).
                        По умолчанию 0.3. # <-- НОВОЕ
  --chunk CHUNK         Максимальное количество токенов в одном фрагменте
                        текста для SigLIP.
                        Используется для разбиения длинных текстов. По
                        умолчанию используется значение из config.py.
  --demo                Запустить демонстрацию на встроенных примерах из
                        data/demo_images/.
  --pipeline-config PIPELINE_CONFIG
                        Путь к JSON-файл конфигурации пайплайна. Определяет,
                        какие метрики включены и их веса по умолчанию. Если не
                        указан, используется стандартная конфигурация.
```

## Структура проекта

Структура проекта следует рекомендациям Cookiecutter Data Science для организации кода и данных.

```
rank_images_project/
├── README.md # Этот файл
├── pyproject.toml # Конфигурация проекта и его основных зависимостей.
# Используется pip install -e . для установки.
├── requirements.txt # (Опционально) Фиксированный список зависимостей, сгенерированный uv pip compile.
# Может использоваться для воспроизводимой установки с pip install -r.
├── constraints.txt # (Опционально) Фиксированные версии критически важных библиотек.
# Используется с pip install -r requirements.txt -c constraints.txt
# для обеспечения совместимости (например, timm==0.6.13).
├── .gitignore # Файлы и папки, игнорируемые Git
├── configs/ # JSON-файлы конфигурации пайплайна
│ ├── default_pipeline.json # Конфигурация по умолчанию
│ ├── caption_focus_pipeline.json # Профиль: фокус на captioning
│ ├── quality_and_alignment_pipeline.json # Профиль: качество и соответствие
│ └── ... # Другие пользовательские профили
├── data/
│ ├── raw/ # (Опционально) Ваши собственные изображения для обработки
│ └── demo_images/ # Демонстрационные изображения и промпты
│ ├── image1.jpg # Пример изображения 1
│ ├── image2.png # Пример изображения 2
│ └── prompts.json # Промпты для демонстрационных изображений
├── notebooks/ # Jupyter ноутбуки для исследований
├── src/
│ └── rank_images/ # Основной пакет Python
│ ├── init.py # Делает каталог пакетом
│ ├── config.py # Глобальные константы
│ ├── device_utils.py # Функции управления устройствами (_to_gpu, _release)
│ ├── models.py # Загрузка и хранение моделей
│ ├── data_processing.py# Вспомогательные функции обработки данных
│ ├── metrics.py # Функции вычисления метрик
│ ├── utils.py # Общие утилиты (нормализация и т.д.)
│ ├── example_metric.py # Пример шаблона для добавления новой метрики
│ ├── pipeline_config.py # Управление конфигурацией пайплайна (JSON)
│ └── ranking.py # Основная логика ранжирования
└── outputs/ # (Игнорируется) Для будущих результатов/промежуточных данных
```

*Пояснение:*

- `pyproject.toml`: Это основной файл конфигурации проекта. Он описывает метаданные проекта (имя, версия, описание) и основные зависимости, включая те, которые требуют специальных флагов установки (--pre, --extra-index-url). Именно этот файл используется pip install -e ..
- `requirements.txt`: Это опциональный файл, обычно генерируемый инструментами типа uv pip compile. Он содержит фиксированный список всех зависимостей с точными версиями, что делает установку воспроизводимой. Его можно использовать с pip install -r requirements.txt.
- `constraints.txt`: Это опциональный файл, содержащий жёсткие ограничения на версии критически важных библиотек (например, timm==0.6.13, datasets==2.13.0, image-reward==1.5). Он используется совместно с requirements.txt: pip install -r requirements.txt -c constraints.txt. Это гарантирует, что даже если requirements.txt был сгенерирован с другими версиями, pip установит именно те версии, которые указаны в constraints.txt, разрешая любые конфликты зависимостей в пользу этих версий.

## Лицензия

Этот проект лицензирован по лицензии MIT - см. файл [LICENSE](LICENSE) для подробностей.
