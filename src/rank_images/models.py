# src/rank_images/models.py
"""
–ó–∞–≥—Ä—É–∑–∫–∞ –∏ —Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞.

–≠—Ç–æ—Ç –º–æ–¥—É–ª—å –æ—Ç–≤–µ—á–∞–µ—Ç –∑–∞ –∑–∞–≥—Ä—É–∑–∫—É –≤—Å–µ—Ö –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –º–æ–¥–µ–ª–µ–π (SigLIP-2, DINOv2,
Florence-2, CLIP-IQA, BLIP-2 ITM, BLIP Caption) –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –∫ –Ω–∏–º –¥–æ—Å—Ç—É–ø
—á–µ—Ä–µ–∑ –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ. –õ–æ–≥–∏–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —É—á–∏—Ç—ã–≤–∞–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å GPU
–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–∞–º—è—Ç–∏.

–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≥–∏–±–∫—É—é –∑–∞–≥—Ä—É–∑–∫—É:
- –ö–∞—Ä—Ç–∞ METRIC_TO_MODELS –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –∫–∞–∫–∏–µ –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
  —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç –∫–∞–∂–¥–æ–π –º–µ—Ç—Ä–∏–∫–µ.
- load_models() –º–æ–∂–µ—Ç –ø—Ä–∏–Ω–∏–º–∞—Ç—å —Å–ø–∏—Å–æ–∫ –≤–∫–ª—é—á—ë–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫ –∏
  –∑–∞–≥—Ä—É–∂–∞—Ç—å —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ –º–æ–¥–µ–ª–∏.
"""
import sys
import logging
from typing import TYPE_CHECKING, List, Optional, Dict, Set
import torch

from torchmetrics.multimodal import CLIPImageQualityAssessment
from transformers import (
    AutoProcessor,
    AutoModel,
    AutoProcessor as FlorenceProcessor,
    AutoModelForCausalLM,
    # --- BLIP-2 ---
    Blip2Processor,
    Blip2ForImageTextRetrieval, # (–¥–ª—è ITM)
    Blip2ForConditionalGeneration, # (–¥–ª—è captioning)
    # -----------------
    BlipProcessor,
    BlipForConditionalGeneration
)

# –ò–º–ø–æ—Ä—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö –∫–æ–Ω—Å—Ç–∞–Ω—Ç
from .config import (
    SIGLIP_MODEL_NAME,
    DINO_MODEL_NAME,
    FLORENCE_MODEL_NAME,
    BLIP2_ITM_MODEL_NAME, # <-- (–¥–ª—è ITM)
    BLIP_CAPTION_MODEL_NAME, # (–¥–ª—è captioning)
    BLIP2_CAPTION_MODEL_NAME, # (–¥–ª—è captioning)
    # ------------------
    FLORENCE_OFFLOAD_FOLDER,
    DTYPE,
    DEVICE_CPU,
)

import ImageReward as RM


# --- –ò–ú–ü–û–†–¢ –î–õ–Ø –ü–ê–ô–ü–õ–ê–ô–ù–ê ---
# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –≤—Å–µ—Ö –º–µ—Ç—Ä–∏–∫
from .pipeline_config import get_all_metrics

# –ò–º–ø–æ—Ä—Ç —É—Ç–∏–ª–∏—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞–º–∏
from .device_utils import _to_gpu, _release

if TYPE_CHECKING:
    # –ò–º–ø–æ—Ä—Ç—ã —Ç–æ–ª—å–∫–æ –¥–ª—è —Ç–∏–ø–∏–∑–∞—Ü–∏–∏, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏—Ö –∏–º–ø–æ—Ä—Ç–æ–≤
    from transformers import (
        AutoProcessor as SiglipProcessor,
        AutoModel as SiglipModel,
        AutoProcessor as DinoProcessor,
        AutoModel as DinoModel,
        AutoProcessor as FlorenceProcessorType,
        AutoModelForCausalLM as FlorenceModel,
        BlipProcessor as BlipCapProc,
        BlipForConditionalGeneration as BlipCapModel,
        Blip2Processor as Blip2Proc,
        Blip2ForImageTextRetrieval as Blip2ITRModel,
        Blip2ForConditionalGeneration as Blip2CapModel,
    )
    from torchmetrics.multimodal import CLIPImageQualityAssessment as IQAMetric
    

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logger = logging.getLogger(__name__)

# --- –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –º–æ–¥–µ–ª–µ–π ---
# –û–Ω–∏ –±—É–¥—É—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∏–º–ø–æ—Ä—Ç–µ —ç—Ç–æ–≥–æ –º–æ–¥—É–ª—è
# –∏/–∏–ª–∏ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ load_models().

# --- CLIP-IQA ---
iqa_metric: Optional['IQAMetric'] = None
"""
CLIPImageQualityAssessment | None: –ú–æ–¥–µ–ª—å CLIP-IQA –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –æ–±—â–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.
                                    –ó–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –æ–¥–∏–Ω —Ä–∞–∑ –∏ –≤—Å–µ–≥–¥–∞ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –Ω–∞ CPU.
"""

# --- SigLIP-2 ---
sig_proc: Optional['SiglipProcessor'] = None
"""
AutoProcessor | None: –ü—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è –º–æ–¥–µ–ª–∏ SigLIP-2. –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ —Ç–µ–∫—Å—Ç.
"""

sig_model: Optional['SiglipModel'] = None
"""
AutoModel | None: –ú–æ–¥–µ–ª—å SigLIP-2 –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å—Ö–æ–∂–µ—Å—Ç–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ —Ç–µ–∫—Å—Ç–∞.
                  –ó–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –Ω–∞ CPU –∏ –≤—Ä–µ–º–µ–Ω–Ω–æ –ø–µ—Ä–µ–º–µ—â–∞–µ—Ç—Å—è –Ω–∞ GPU –≤–æ –≤—Ä–µ–º—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞.
"""

# --- DINOv2 ---
dino_proc: Optional['DinoProcessor'] = None
"""
AutoProcessor | None: –ü—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è –º–æ–¥–µ–ª–∏ DINOv2. –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.
"""

dino_model: Optional['DinoModel'] = None
"""
AutoModel | None: –ú–æ–¥–µ–ª—å DINOv2 –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.
                  –ó–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –Ω–∞ CPU –∏ –≤—Ä–µ–º–µ–Ω–Ω–æ –ø–µ—Ä–µ–º–µ—â–∞–µ—Ç—Å—è –Ω–∞ GPU –≤–æ –≤—Ä–µ–º—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞.
"""

# --- Florence-2 ---
flor_proc: Optional['FlorenceProcessorType'] = None
"""
AutoProcessor | None: –ü—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è –º–æ–¥–µ–ª–∏ Florence-2. –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ —Ç–µ–∫—Å—Ç.
"""

flor_model: Optional['FlorenceModel'] = None
"""
AutoModelForCausalLM | None: –ú–æ–¥–µ–ª—å Florence-2 –¥–ª—è –∑–∞–¥–∞—á –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏ grounding.
                             –ó–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è —Å `device_map="auto"` –¥–ª—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è.
"""

# --- BLIP-2 ---
blip2_processor: Optional['Blip2Proc'] = None
"""
Blip2Processor | None: –ü—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è –º–æ–¥–µ–ª–∏ BLIP-2 ITM.
"""

blip2_model: Optional['Blip2ITRModel'] = None
"""
Blip2ForConditionalGeneration | None: –ú–æ–¥–µ–ª—å BLIP-2 –¥–ª—è Image-Text Matching.
                                      –ó–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –Ω–∞ CPU –∏ –≤—Ä–µ–º–µ–Ω–Ω–æ –ø–µ—Ä–µ–º–µ—â–∞–µ—Ç—Å—è –Ω–∞ GPU.
"""
# -------------

# --- BLIP Caption ---
blip_cap_processor: Optional['BlipCapProc'] = None
"""
BlipProcessor | None: –ü—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è –º–æ–¥–µ–ª–∏ BLIP Caption.
"""

blip_cap_model: Optional['BlipCapModel'] = None
"""
BlipForConditionalGeneration | None: –ú–æ–¥–µ–ª—å BLIP –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–ø–∏—Å–∞–Ω–∏–π (captioning).
                                     –ó–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –Ω–∞ CPU –∏ –≤—Ä–µ–º–µ–Ω–Ω–æ –ø–µ—Ä–µ–º–µ—â–∞–µ—Ç—Å—è –Ω–∞ GPU.
"""
# --- BLIP-2 Caption ---
blip2_cap_processor:  Optional['Blip2Proc'] = None
"""
Blip2Processor: –ü—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è –º–æ–¥–µ–ª–∏ BLIP-2 Caption (ConditionalGeneration).
"""

blip2_cap_model: Optional['Blip2CapModel'] = None
"""
Blip2ForConditionalGeneration: –ú–æ–¥–µ–ª—å BLIP-2 –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–ø–∏—Å–∞–Ω–∏–π (captioning).
                              –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è blip_2_caption_bertscore.
"""

imr_model  = None        # reward-–º–æ–¥–µ–ª—å
"""
¬´—á–µ–ª–æ–≤–µ—á–µ—Å–∫–∞—è¬ª –æ—Ü–µ–Ω–∫–∞ —Å—Ç–∏–ª—è/–∫–æ–º–ø–æ–∑–∏—Ü–∏–∏.
"""

tifa_evaluator = None  # TIFA Evaluator
"""TIFA Evaluator: –ú–æ–¥–µ–ª—å –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ –º–µ—Ç—Ä–∏–∫–∞–º TIFA.
"""

# --------------------

# --- –ö–∞—Ä—Ç–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –º–µ—Ç—Ä–∏–∫ –∏ –º–æ–¥–µ–ª–µ–π ---
# –≠—Ç–æ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ–µ –º–µ—Å—Ç–æ, –æ–ø—Ä–µ–¥–µ–ª—è—é—â–µ–µ, –∫–∞–∫–∏–µ –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
# –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã –¥–ª—è –∫–∞–∂–¥–æ–π –º–µ—Ç—Ä–∏–∫–∏. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è load_models() –∏ –¥—Ä—É–≥–∏–º–∏ –º–æ–¥—É–ª—è–º–∏.
METRIC_TO_MODELS: Dict[str, List[str]] = {
    "sig": ["sig_proc", "sig_model"],
    "flor": ["flor_proc", "flor_model"],
    "iqa": ["iqa_metric"],
    "dino": ["dino_proc", "dino_model"],
    "blip2": ["blip2_processor", "blip2_model"],
    "blip_cap": ["blip_cap_processor", "blip_cap_model"],
    # –î–ª—è blip2_caption_bertscore (–Ω–æ–≤–∞—è –º–µ—Ç—Ä–∏–∫–∞) –ø–æ—Ç—Ä–µ–±—É–µ—Ç—Å—è blip2_caption_model
    "blip2_cap": ["blip2_cap_processor", "blip2_cap_model"], 
    "imr": ["imr_model"], 
    "tifa": ["tifa_evaluator"],  # –î–æ–±–∞–≤–ª—è–µ–º TIFA Evaluator
}
"""
Dict[str, List[str]]: –ö–∞—Ä—Ç–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –º–µ–∂–¥—É –∏–º–µ–Ω–∞–º–∏ –º–µ—Ç—Ä–∏–∫ –∏
                      —Å–ø–∏—Å–∫–∞–º–∏ –∏–º—ë–Ω –≥–ª–æ–±–∞–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π/–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–æ–≤,
                      –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–ª—è –∏—Ö —Ä–∞–±–æ—Ç—ã.

                      –≠—Ç–æ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫ –∏—Å—Ç–∏–Ω—ã –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
                      –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –º–µ—Ç—Ä–∏–∫ –æ—Ç –º–æ–¥–µ–ª–µ–π.
"""
# --------------------------------------------

# --- –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π ---
def _load_florence(local_only: bool) -> AutoModelForCausalLM:
    """
    –í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ Florence-2.

    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç `device_map="auto"` –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å–ª–æ—ë–≤,
    `torch_dtype=torch.float16` –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏ (–µ—Å–ª–∏ GPU –¥–æ—Å—Ç—É–ø–µ–Ω),
    `low_cpu_mem_usage=True` –¥–ª—è —Å–Ω–∏–∂–µ–Ω–∏—è –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è RAM –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ,
    –∏ `offload_folder` –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–ª–æ—ë–≤, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –ø–æ–º–µ—â–∞—é—Ç—Å—è –≤ –ø–∞–º—è—Ç—å.

    Args:
        local_only (bool): –ï—Å–ª–∏ True, –∑–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å —Ç–æ–ª—å–∫–æ –∏–∑ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∫—ç—à–∞.
                           –ï—Å–ª–∏ False, –ø–æ–∑–≤–æ–ª—è–µ—Ç –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞.

    Returns:
        AutoModelForCausalLM: –ó–∞–≥—Ä—É–∂–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å Florence-2.
    """
    return AutoModelForCausalLM.from_pretrained(
        FLORENCE_MODEL_NAME,
        trust_remote_code=True,
        device_map="auto",  # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞–º
        torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
        low_cpu_mem_usage=True,  # –≠–∫–æ–Ω–æ–º–∏—è RAM –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ
        offload_folder=FLORENCE_OFFLOAD_FOLDER,  # –ü–∞–ø–∫–∞ –¥–ª—è –æ—Ñ—Ñ–ª–æ–∞–¥–∞
        local_files_only=local_only,  # –¢–æ–ª—å–∫–æ –ª–æ–∫–∞–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã –∏–ª–∏ —Ä–∞–∑—Ä–µ—à–∏—Ç—å –∑–∞–≥—Ä—É–∑–∫—É
    )

# --- –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π ---
# src/rank_images/models.py
def load_models(enabled_metrics_list: Optional[List[str]] = None) -> None:
    """
    –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª–∏ –ø—Ä–æ–µ–∫—Ç–∞.

    –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –≤—ã–∑–≤–∞–Ω–∞ –æ–¥–∏–Ω —Ä–∞–∑ –ø–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π.
    –û–Ω–∞ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏—è –≥–ª–æ–±–∞–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π.

    Args:
        enabled_metrics_list (List[str] | None): –°–ø–∏—Å–æ–∫ –≤–∫–ª—é—á—ë–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫.
            –ï—Å–ª–∏ None, –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è –≤—Å–µ –º–æ–¥–µ–ª–∏.
    """
    global iqa_metric, sig_proc, sig_model, dino_proc, dino_model, flor_proc, flor_model
    global blip2_processor, blip2_model
    global blip_cap_processor, blip_cap_model
    # --- –î–û–ë–ê–í–ò–¢–¨ –ù–û–í–´–ï –ì–õ–û–ë–ê–õ–¨–ù–´–ï –ü–ï–†–ï–ú–ï–ù–ù–´–ï ---
    global blip2_cap_processor, blip2_cap_model
    global imr_model
    # --------------------------------------------

    logger.info("–ù–∞—á–∏–Ω–∞—é –∑–∞–≥—Ä—É–∑–∫—É –º–æ–¥–µ–ª–µ–π (–Ω–∞ CPU)...")
    # --- –û–ü–†–ï–î–ï–õ–ï–ù–ò–ï, –ö–ê–ö–ò–ï –ú–û–î–ï–õ–ò –ù–£–ñ–ù–û –ó–ê–ì–†–£–ñ–ê–¢–¨ ---
    models_to_load: Set[str] = set()
    if enabled_metrics_list is None:
        # –ï—Å–ª–∏ —Å–ø–∏—Å–æ–∫ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω, –∑–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –º–æ–¥–µ–ª–∏
        logger.debug("–°–ø–∏—Å–æ–∫ –º–µ—Ç—Ä–∏–∫ –Ω–µ —É–∫–∞–∑–∞–Ω. –ó–∞–≥—Ä—É–∂–∞—é –≤—Å–µ –º–æ–¥–µ–ª–∏.")
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—É—é –∫–∞—Ä—Ç—É METRIC_TO_MODELS
        models_to_load.update(sum(METRIC_TO_MODELS.values(), []))
    elif not enabled_metrics_list:
        # –ï—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫, –Ω–∏—á–µ–≥–æ –Ω–µ –∑–∞–≥—Ä—É–∂–∞–µ–º
        logger.info("–°–ø–∏—Å–æ–∫ –º–µ—Ç—Ä–∏–∫ –ø—É—Å—Ç. –ù–∏–∫–∞–∫–∏–µ –º–æ–¥–µ–ª–∏ –Ω–µ –±—É–¥—É—Ç –∑–∞–≥—Ä—É–∂–µ–Ω—ã.")
        return
    else:
        # –ï—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω —Å–ø–∏—Å–æ–∫, –∑–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏ —Ç–æ–ª—å–∫–æ –¥–ª—è –≤–∫–ª—é—á—ë–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫
        logger.debug(f"–ó–∞–≥—Ä—É–∂–∞—é –º–æ–¥–µ–ª–∏ —Ç–æ–ª—å–∫–æ –¥–ª—è –º–µ—Ç—Ä–∏–∫: {enabled_metrics_list}")
        for metric_name in enabled_metrics_list:
            # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –¥–ª—è –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ–π –∫–∞—Ä—Ç—ã
            required_models = METRIC_TO_MODELS.get(metric_name, [])
            models_to_load.update(required_models)
            logger.debug(f"  –ú–µ—Ç—Ä–∏–∫–∞ '{metric_name}' —Ç—Ä–µ–±—É–µ—Ç –º–æ–¥–µ–ª–∏: {required_models}")
    
    logger.debug(f"–ò—Ç–æ–≥–æ–≤—ã–π —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏: {sorted(models_to_load)}")
    # ------------------------------------------

    # --- –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π ---
    try:
        # –ó–∞–≥—Ä—É–∑–∫–∞ CLIP-IQA
        if "iqa_metric" in models_to_load:
            logger.info("–ù–∞—á–∏–Ω–∞—é –∑–∞–≥—Ä—É–∑–∫—É –º–æ–¥–µ–ª–∏ CLIP-IQA...")
            iqa_metric = CLIPImageQualityAssessment("clip_iqa").to(DEVICE_CPU).eval()
            logger.info("–ú–æ–¥–µ–ª—å CLIP-IQA –∑–∞–≥—Ä—É–∂–µ–Ω–∞.")
        else:
            iqa_metric = None
            logger.info("–ú–æ–¥–µ–ª—å CLIP-IQA –ø—Ä–æ–ø—É—â–µ–Ω–∞ (–Ω–µ –≤–∫–ª—é—á–µ–Ω–∞).")
        # --- –ö–æ–Ω–µ—Ü –∑–∞–≥—Ä—É–∑–∫–∏ CLIP-IQA --

        # –ó–∞–≥—Ä—É–∑–∫–∞ SigLIP-2
        if "sig_proc" in models_to_load and "sig_model" in models_to_load:
            logger.info("–ù–∞—á–∏–Ω–∞—é –∑–∞–≥—Ä—É–∑–∫—É –º–æ–¥–µ–ª–∏ SigLIP-2...")
            sig_proc = AutoProcessor.from_pretrained(SIGLIP_MODEL_NAME)
            sig_model = AutoModel.from_pretrained(
                SIGLIP_MODEL_NAME, torch_dtype=DTYPE, device_map="cpu"
            ).eval()
            logger.info("–ú–æ–¥–µ–ª—å SigLIP-2 –∑–∞–≥—Ä—É–∂–µ–Ω–∞.")
        else:
            sig_proc, sig_model = None, None
            logger.info("–ú–æ–¥–µ–ª—å SigLIP-2 –ø—Ä–æ–ø—É—â–µ–Ω–∞ (–Ω–µ –≤–∫–ª—é—á–µ–Ω–∞).")
        # --- –ö–æ–Ω–µ—Ü –∑–∞–≥—Ä—É–∑–∫–∏ SigLIP-2 ---
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ DINOv2
        if "dino_proc" in models_to_load and "dino_model" in models_to_load:
            logger.info("–ù–∞—á–∏–Ω–∞—é –∑–∞–≥—Ä—É–∑–∫—É –º–æ–¥–µ–ª–∏ DINOv2...")
            dino_proc = AutoProcessor.from_pretrained(DINO_MODEL_NAME)
            dino_model = AutoModel.from_pretrained(
                DINO_MODEL_NAME, torch_dtype=DTYPE, device_map="cpu"
            ).eval()
            logger.info("–ú–æ–¥–µ–ª—å DINOv2 –∑–∞–≥—Ä—É–∂–µ–Ω–∞.")
        else:
            dino_proc, dino_model = None, None
            logger.info("–ú–æ–¥–µ–ª—å DINOv2 –ø—Ä–æ–ø—É—â–µ–Ω–∞ (–Ω–µ –≤–∫–ª—é—á–µ–Ω–∞).")
        # --- –ö–æ–Ω–µ—Ü –∑–∞–≥—Ä—É–∑–∫–∏ DINOv2 ---

        # –ó–∞–≥—Ä—É–∑–∫–∞ Florence-2
        if "flor_proc" in models_to_load and "flor_model" in models_to_load:
            logger.info("–ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∏—Ç—å Florence-2 –∏–∑ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∫—ç—à–∞...")
            try:
                flor_model = _load_florence(local_only=True)
                logger.info("Florence-2 —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∫—ç—à–∞.")
            except Exception as e:
                logger.error(f"Florence-2 –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –ª–æ–∫–∞–ª—å–Ω–æ ({e}), –Ω–∞—á–∏–Ω–∞—é –∑–∞–≥—Ä—É–∑–∫—É –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞...")
                try:
                    flor_model = _load_florence(local_only=False)
                    logger.info("Florence-2 —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞.")
                except Exception as e_internet:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ Florence-2 –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞: {e_internet}", exc_info=True)
                    flor_model = None
                    logger.warning("–ú–æ–¥–µ–ª—å Florence-2 –Ω–µ –±—É–¥–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–∞.")
            
            if flor_model is not None:
                flor_proc = FlorenceProcessor.from_pretrained(FLORENCE_MODEL_NAME, trust_remote_code=True)
                logger.info("–ü—Ä–æ—Ü–µ—Å—Å–æ—Ä Florence-2 –∑–∞–≥—Ä—É–∂–µ–Ω.")
            # --- –ö–æ–Ω–µ—Ü –∑–∞–≥—Ä—É–∑–∫–∏ Florence-2 ---


        # –ó–∞–≥—Ä—É–∑–∫–∞ BLIP-2 ITM
        if "blip2_processor" in models_to_load and "blip2_model" in models_to_load:
            logger.info("–ù–∞—á–∏–Ω–∞—é –∑–∞–≥—Ä—É–∑–∫—É –º–æ–¥–µ–ª–∏ BLIP-2...")
            blip2_processor = Blip2Processor.from_pretrained(BLIP2_ITM_MODEL_NAME)
            blip2_model = Blip2ForImageTextRetrieval.from_pretrained(
                BLIP2_ITM_MODEL_NAME,
                torch_dtype=DTYPE,
                device_map="cpu",
                low_cpu_mem_usage=True, # <-- –î–æ–±–∞–≤–∏—Ç—å
            ).eval()
            logger.info("–ú–æ–¥–µ–ª—å BLIP-2 (ITM) –∑–∞–≥—Ä—É–∂–µ–Ω–∞.")
        else:
            blip2_processor, blip2_model = None, None
            logger.info("–ú–æ–¥–µ–ª—å BLIP-2 (ITM) –ø—Ä–æ–ø—É—â–µ–Ω–∞ (–Ω–µ –≤–∫–ª—é—á–µ–Ω–∞).")
        # --- –ö–æ–Ω–µ—Ü –∑–∞–≥—Ä—É–∑–∫–∏ BLIP-2 ---

        # –ó–∞–≥—Ä—É–∑–∫–∞ BLIP Caption
        if "blip_cap_processor" in models_to_load and "blip_cap_model" in models_to_load:
            logger.info("–ù–∞—á–∏–Ω–∞—é –∑–∞–≥—Ä—É–∑–∫—É –º–æ–¥–µ–ª–∏ BLIP Caption...")
            blip_cap_processor = BlipProcessor.from_pretrained(BLIP_CAPTION_MODEL_NAME)
            blip_cap_model = BlipForConditionalGeneration.from_pretrained(
                BLIP_CAPTION_MODEL_NAME,
                torch_dtype=DTYPE,
                device_map="cpu"
            ).eval()
            logger.info("–ú–æ–¥–µ–ª—å BLIP Caption –∑–∞–≥—Ä—É–∂–µ–Ω–∞.")
        else:
            blip_cap_processor, blip_cap_model = None, None
            logger.info("–ú–æ–¥–µ–ª—å BLIP Caption –ø—Ä–æ–ø—É—â–µ–Ω–∞ (–Ω–µ –≤–∫–ª—é—á–µ–Ω–∞).")
        # --- –ö–æ–Ω–µ—Ü –∑–∞–≥—Ä—É–∑–∫–∏ BLIP Caption ---

        # --- –ó–∞–≥—Ä—É–∑–∫–∞ BLIP-2 Caption ---
        if "blip2_cap_processor" in models_to_load and "blip2_cap_model" in models_to_load:
            logger.info("–ù–∞—á–∏–Ω–∞—é –∑–∞–≥—Ä—É–∑–∫—É –º–æ–¥–µ–ª–∏ BLIP-2 Caption...")
            try:
                # BLIP-2 Caption –±—É–¥–µ—Ç –∑–∞–≥—Ä—É–∂–∞—Ç—å—Å—è –Ω–∞ CPU –∏ –ø–µ—Ä–µ–º–µ—â–∞—Ç—å—Å—è –Ω–∞ GPU –≤–æ –≤—Ä–µ–º—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
                blip2_cap_processor = Blip2Processor.from_pretrained(BLIP2_CAPTION_MODEL_NAME) # <-- –ò—Å–ø–æ–ª—å–∑—É–µ–º BLIP2Processor
                blip2_cap_model = Blip2ForConditionalGeneration.from_pretrained( # <-- –ò—Å–ø–æ–ª—å–∑—É–µ–º Blip2ForConditionalGeneration
                    BLIP2_CAPTION_MODEL_NAME, # <-- –ò–º—è –º–æ–¥–µ–ª–∏ –∏–∑ config.py
                    torch_dtype=DTYPE,
                    device_map="cpu"
                ).eval()
                logger.info("–ú–æ–¥–µ–ª—å BLIP-2 Caption –∑–∞–≥—Ä—É–∂–µ–Ω–∞.")
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–∏ BLIP-2 Caption: {e}", exc_info=True)
                # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ä–∞–±–æ—Ç—É –±–µ–∑ BLIP-2 Caption
                blip2_cap_processor = None
                blip2_cap_model = None
                logger.warning("–ú–æ–¥–µ–ª—å BLIP-2 Caption –Ω–µ –±—É–¥–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–∞.")
        else:
            blip2_cap_processor, blip2_cap_model = None, None
            logger.info("–ú–æ–¥–µ–ª—å BLIP-2 Caption –ø—Ä–æ–ø—É—â–µ–Ω–∞ (–Ω–µ –≤–∫–ª—é—á–µ–Ω–∞).")
        # --- –ö–æ–Ω–µ—Ü –∑–∞–≥—Ä—É–∑–∫–∏ BLIP-2 Caption ---

        #--- –ó–∞–≥—Ä—É–∑–∫–∞ ImageReward ---
        if "imr" in enabled_metrics_list and imr_model is None:
            imr_model = RM.load("ImageReward-v1.0")
            imr_model.device = torch.device("cpu")   # –≤–∞–∂–Ω—ã–π –ø–µ—Ä–µ–∫–ª—é—á–∞—Ç–µ–ª—å
            imr_model.to("cpu")
            #--- –ö–æ–Ω–µ—Ü –∑–∞–≥—Ä—É–∑–∫–∏ ImageReward ---

        #--- –ó–∞–≥—Ä—É–∑–∫–∞ TIFA ---
        if "tifa" in enabled_metrics_list and tifa_evaluator is None:
            from tifa import TifaEvaluator
            tifa_evaluator = TifaEvaluator(model="blip2_base")  # CPU
            logger.info("üü¢ TIFA evaluator loaded")
        # --- –ó–∞–≥—Ä—É–∑–∫–∞ TIFA Evaluator ---
        
        logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")


    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–µ–π", exc_info=True)
        logger.warning("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π –Ω–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")
    # --- –ö–æ–Ω–µ—Ü –∑–∞–≥—Ä—É–∑–∫–∏ BLIP Caption ---
# --- –ö–æ–Ω–µ—Ü –º–æ–¥—É–ª—è ---