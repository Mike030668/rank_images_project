# src/rank_images/device_utils.py
"""
Утилиты для управления размещением моделей на устройствах (CPU/GPU).

Этот модуль предоставляет функции для временного перемещения моделей PyTorch
на GPU для выполнения вычислений и последующего возврата их на CPU для
освобождения видеопамяти. Это особенно полезно при ограниченной VRAM.

Примечание:
    Эти функции НЕ применяются к Florence-2, так как она загружается с
    `device_map="auto"`, что уже оптимально распределяет слои.
"""
import torch
from .config import USE_GPU, DEVICE_GPU, DEVICE_CPU, DTYPE

def _to_gpu(model: torch.nn.Module) -> torch.nn.Module:
    """
    Временно перемещает модель на GPU (если доступен).

    Перемещает модель на устройство GPU и устанавливает для неё тип данных,
    определённый в конфигурации (обычно float16 для GPU).

    Args:
        model (torch.nn.Module): Модель PyTorch для перемещения.

    Returns:
        torch.nn.Module: Модель, перемещённая на GPU (если доступен).
                         В противном случае возвращается исходная модель.
    """
    if USE_GPU:
        # Перемещаем модель на GPU и устанавливаем тип данных
        return model.to(DEVICE_GPU).to(dtype=DTYPE)
    # Если GPU недоступен, возвращаем модель без изменений
    return model

def _release(model: torch.nn.Module) -> None:
    """
    Возвращает модель с GPU обратно на CPU и очищает кэш CUDA.

    Эта функция используется в паре с `_to_gpu` для освобождения видеопамяти
    после завершения вычислений.

    Args:
        model (torch.nn.Module): Модель PyTorch для возврата на CPU.
    """
    if USE_GPU:
        # Перемещаем модель обратно на CPU
        model.to(DEVICE_CPU)
        # Очищаем кэш CUDA, чтобы освободить неиспользуемую память
        torch.cuda.empty_cache()

# Примечание: Эти функции являются внутренними и не предназначены для
# импорта вне этого модуля. Однако, они могут быть импортированы
# другими модулями проекта, если это необходимо для работы с моделями.